{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.streaming import DataStreamWriter, DataStreamReader\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "spark: SparkSession = (\n",
    "    SparkSession.builder.appName(\"stream_sentiment_analysis\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setCheckpointDir(\"../checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PipelineModel.load(\"../model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set streamReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"polarity FLOAT, id LONG, date_time TIMESTAMP, query STRING, user STRING, text STRING\"\n",
    "timestampformat = \"EEE MMM dd HH:mm:ss zzz yyyy\"\n",
    "\n",
    "spark_reader: DataStreamReader = spark.readStream.schema(schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prune and clean incoming data, also, use trained model to find predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "user_regex = r\"(@\\w{1,15})\"\n",
    "url_regex = r\"((https?|ftp|file):\\/{2,3})+([-\\w+&@#/%=~|$?!:,.]*)|(www.)+([-\\w+&@#/%=~|$?!:,.]*)\"\n",
    "email_regex = r\"[\\w.-]+@[\\w.-]+\\.[a-zA-Z]{1,}\"\n",
    "\n",
    "\n",
    "@udf\n",
    "def html_unescape(s: str):\n",
    "    if isinstance(s, str):\n",
    "        return html.unescape(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = (\n",
    "    spark_reader.csv(\n",
    "        \"../stream/\", timestampFormat=timestampformat, quote='\"', header=False\n",
    "    )\n",
    "    .select(\"id\", \"date_time\", \"user\", \"text\")\n",
    "    .withColumn(\"text\", f.regexp_replace(\"text\", url_regex, \"\"))\n",
    "    .withColumn(\"text\", f.regexp_replace(\"text\", email_regex, \"\"))\n",
    "    .withColumn(\"text\", f.regexp_replace(\"text\", user_regex, \"\"))\n",
    "    .withColumn(\"text\", f.regexp_replace(\"text\", \"#\", \" \"))\n",
    "    .withColumn(\"text\", html_unescape(f.col(\"text\")))\n",
    "    .withColumn(\"text\", f.regexp_replace(\"text\", \"[^a-zA-Z']\", \" \"))\n",
    "    .withColumn(\"text\", f.regexp_replace(\"text\", \" +\", \" \"))\n",
    "    .withColumn(\"text\", f.trim(\"text\"))\n",
    "    .filter(\"text != ''\")\n",
    "    .na.drop(subset=\"text\")\n",
    "    .coalesce(1)\n",
    ")\n",
    "\n",
    "predictions = model.transform(dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the number of negative, positive assigned comments with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_count = dataframe.select(f.approx_count_distinct(\"user\").alias('number of users'), f.current_timestamp().alias('timestamp'))\n",
    "\n",
    "result = (\n",
    "    predictions.select(\n",
    "        \"prediction\",\n",
    "        f.when(f.col(\"prediction\") == 1.0, 1).otherwise(0).alias(\"positive\"),\n",
    "        f.when(f.col(\"prediction\") == 0.0, 1).otherwise(0).alias(\"negative\"),\n",
    "        f.lit(1).alias(\"total\"),\n",
    "    )\n",
    "    .agg(\n",
    "        f.sum(\"positive\").alias(\"positive tweets\"),\n",
    "        f.sum(\"negative\").alias(\"negative tweets\"),\n",
    "        f.sum(\"total\").alias(\"total tweets\"),\n",
    "        f.round(f.avg(\"prediction\"), 2).alias(\"average polarity\")\n",
    "    )\n",
    "    .select(\"*\", f.current_timestamp().alias(\"timestamp\"))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set streamWriter and activate streaming query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream is Active\n"
     ]
    }
   ],
   "source": [
    "if dataframe.isStreaming:\n",
    "    stream_writer: DataStreamWriter = (\n",
    "        result.writeStream.queryName(\"result\")\n",
    "        .trigger(processingTime=\"5 seconds\")\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"memory\")\n",
    "    )\n",
    "\n",
    "    query = stream_writer.start()\n",
    "\n",
    "    print(f\"Stream is {'Active' if query.isActive else 'Not Active'}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run query every 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+------------+----------------+-----------------------+\n",
      "|positive tweets|negative tweets|total tweets|average polarity|timestamp              |\n",
      "+---------------+---------------+------------+----------------+-----------------------+\n",
      "|22             |28             |50          |0.44            |2023-06-17 15:27:24.547|\n",
      "+---------------+---------------+------------+----------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-4549b729ec1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"select * from {query.name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while True:\n",
    "    spark.sql(f\"select * from {query.name}\").show(truncate=False)\n",
    "    sleep(5)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
